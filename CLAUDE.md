# CLAUDE.md â€” Job Hunter OS Â· MÃ©moire Projet

> Ce fichier sert de mÃ©moire persistante pour Claude Code. Il contient le contexte, les dÃ©cisions techniques et les conventions du projet. **Lis ce fichier en premier Ã  chaque session.**

---

## ğŸ¯ Objectif du Projet

**Job Hunter OS** est un tableau de bord personnel pour centraliser et automatiser la recherche d'emploi :
- Suivre toutes les candidatures dans un pipeline visuel (Kanban)
- Scraper des offres depuis Indeed et Welcome to the Jungle
- DÃ©tecter automatiquement les rÃ©ponses reÃ§ues par email (Gmail)
- Exporter les donnÃ©es en Excel

**Public cible** : un utilisateur unique (moi), en local.

---

## ğŸ—ï¸ Stack Technique

| Composant | Technologie | Version min |
|-----------|-------------|-------------|
| Frontend | Streamlit | 1.30+ |
| Backend | Python | 3.11+ |
| Base de donnÃ©es | SQLite (stdlib) | â€” |
| Scraping | requests + BeautifulSoup4 | â€” |
| Emails | Gmail API (google-api-python-client) | â€” |
| Export | pandas + openpyxl | â€” |
| Graphiques | plotly | â€” |

---

## ğŸ“ Structure du Projet

```
job-hunter-os/
â”œâ”€â”€ CLAUDE.md              # CE FICHIER â€” mÃ©moire projet
â”œâ”€â”€ README.md              # Doc utilisateur
â”œâ”€â”€ requirements.txt       # DÃ©pendances
â”œâ”€â”€ app.py                 # Point d'entrÃ©e Streamlit
â”œâ”€â”€ config.py              # Constantes, chemins
â”œâ”€â”€ database.py            # SQLite : connexion + CRUD
â”œâ”€â”€ models.py              # Dataclasses
â”œâ”€â”€ pages/                 # Pages Streamlit
â”‚   â”œâ”€â”€ dashboard.py       # Kanban
â”‚   â”œâ”€â”€ add_candidature.py # Formulaire
â”‚   â”œâ”€â”€ search_offers.py   # Recherche offres
â”‚   â”œâ”€â”€ emails.py          # Suivi emails
â”‚   â””â”€â”€ stats.py           # Statistiques
â”œâ”€â”€ scrapers/              # Modules de scraping
â”‚   â”œâ”€â”€ base.py            # Classe abstraite
â”‚   â”œâ”€â”€ indeed.py
â”‚   â””â”€â”€ wttj.py
â”œâ”€â”€ email_client/          # IntÃ©gration Gmail
â”‚   â”œâ”€â”€ gmail.py
â”‚   â””â”€â”€ classifier.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ export.py          # Export Excel/CSV
â”‚   â””â”€â”€ anti_block.py      # Anti-blocage (headers, dÃ©lais)
â”œâ”€â”€ tests/
â”œâ”€â”€ data/                  # BDD SQLite (gÃ©nÃ©rÃ©e)
â””â”€â”€ credentials/           # OAuth2 (gitignored)
```

---

## ğŸ—„ï¸ SchÃ©ma Base de DonnÃ©es

### Table `candidatures`
```sql
CREATE TABLE candidatures (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    entreprise TEXT NOT NULL,
    poste TEXT NOT NULL,
    url TEXT,
    statut TEXT DEFAULT 'a_postuler',  -- a_postuler|postule|relance|entretien|offre|refus
    date_candidature DATE,
    date_relance DATE,
    notes TEXT,
    source TEXT,          -- manuel|indeed|wttj|csv
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Table `offres_scrapees`
```sql
CREATE TABLE offres_scrapees (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    titre TEXT NOT NULL,
    entreprise TEXT,
    lieu TEXT,
    url TEXT UNIQUE,      -- dÃ©doublication par URL
    source TEXT,          -- indeed|wttj
    date_scraping TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    importee BOOLEAN DEFAULT 0  -- converti en candidature ?
);
```

### Table `emails_recus`
```sql
CREATE TABLE emails_recus (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    gmail_id TEXT UNIQUE,
    expediteur TEXT,
    sujet TEXT,
    date_reception TIMESTAMP,
    classification TEXT,  -- positif|negatif|relance|inconnu
    candidature_id INTEGER REFERENCES candidatures(id),
    lu BOOLEAN DEFAULT 0
);
```

---

## ğŸ“ Conventions de Code

### Style
- **Python** : PEP 8, docstrings Google-style
- **Nommage** : `snake_case` partout (fichiers, fonctions, variables)
- **Imports** : stdlib â†’ third-party â†’ local, sÃ©parÃ©s par ligne vide
- **Type hints** : obligatoires sur les signatures de fonctions

### Streamlit
- Chaque page = un fichier dans `pages/`
- `st.set_page_config()` uniquement dans `app.py`
- Utiliser `st.session_state` pour l'Ã©tat entre les pages
- Utiliser `st.cache_data` pour les requÃªtes BDD

### Base de donnÃ©es
- Toutes les requÃªtes passent par `database.py`, jamais de SQL direct dans les pages
- Utiliser des paramÃ¨tres `?` pour les requÃªtes (jamais de f-string SQL)
- Toujours fermer les connexions (context manager `with`)

### Scraping
- HÃ©riter de `BaseScraper` dans `scrapers/base.py`
- DÃ©lai alÃ©atoire entre requÃªtes : `time.sleep(random.uniform(2, 5))`
- Rotation des User-Agents via `utils/anti_block.py`
- Si erreur HTTP 403/429 â†’ log l'erreur, ne pas crash, proposer le fallback CSV

### Gestion d'erreurs
- Try/except autour de tout appel rÃ©seau
- Messages utilisateur clairs via `st.error()` / `st.warning()`
- Logging dans un fichier `data/app.log`

---

## ğŸš€ Commandes Utiles

```bash
# Installation
pip install -r requirements.txt

# Lancement
streamlit run app.py

# Tests
python -m pytest tests/ -v

# Linter
python -m flake8 --max-line-length 100
```

---

## ğŸ”‘ Statuts de Candidature (Pipeline)

```
Ã€ postuler â†’ PostulÃ© â†’ RelancÃ© â†’ Entretien â†’ Offre reÃ§ue
                                              â†’ Refus
```

Les statuts valides sont : `a_postuler`, `postule`, `relance`, `entretien`, `offre`, `refus`

---

## âš ï¸ Points d'Attention

1. **Ne jamais commiter `credentials/`** â€” contient les tokens OAuth2 Gmail
2. **SQLite en mode WAL** â€” activer `PRAGMA journal_mode=WAL` pour la performance
3. **Scraping fragile** â€” les sÃ©lecteurs CSS peuvent changer â†’ toujours tester avant un merge
4. **Gmail quota** â€” max ~250 requÃªtes/jour sur le tier gratuit, mettre un cache
5. **Pas de multi-thread** â€” Streamlit est single-thread, ne pas lancer de scraping lourd en synchrone â†’ utiliser `st.spinner()` et limiter Ã  50 rÃ©sultats

---

## ğŸ“‹ Roadmap RÃ©sumÃ©e

| Phase | Contenu | DÃ©pendances |
|-------|---------|-------------|
| 0 | Setup projet, BDD, structure | Aucune |
| 1 | Dashboard Kanban, formulaire, import/export | Phase 0 |
| 2 | Scrapers Indeed + WTTJ | Phase 0 |
| 3 | IntÃ©gration Gmail | Phase 0 + credentials Google |
| 4 | Stats, polish, tests | Phases 1-3 |
